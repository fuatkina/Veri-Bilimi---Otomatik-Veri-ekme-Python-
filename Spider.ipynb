{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mature-ozone",
   "metadata": {},
   "source": [
    "## Spider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8242b6-f9fd-4cd6-99ef-451bb735bfca",
   "metadata": {},
   "source": [
    "Spider alternatifi çok sayıda sayfayı indirmek istediğimizde daha hızlı çalışıyor. Bunun için sınıf ismini verdiğimiz nesnelere kısa bir göz atalım. Nesne tabanlı bir programlama dili olluğu için Python'da neredeyse her şey bir sınıf olarak tasarlanır. Sınıf (class) kendisinden örnek oluşturulabilmesi ve iç içe fonksiyonlar çalıştırabilmesi yönüyle programlama için çok önemli bir araçtır. Sınıflara çeşitli özellik ve yöntemler atanabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f56cf-abd1-4e6f-be70-3b6be308def3",
   "metadata": {},
   "source": [
    "#### Nasıl çalışır?\n",
    "\n",
    "Aşağıdaki kodda IMDB_Spider isimli bir sınıf tanımlayabilirsiniz. Bu sınıf scrapy kütüphanesinin Spider metodunu çalıştırıyor. İçerikteki ```start_requests``` fonksiyonu ilk olarak işlemi başlatmaya yarıyor. Bu aşamada indirme işleminin başlayacağı ilk sayfayı tanımlayabilirsiniz. Ardından class boyunca modifiye edilecek olan ve fonksiyondan fonksiyona tanışan  ```self``` parametresine gerekli müdahaleyi yaparak bir sonraki fonksiyona (```parse_front```) geçiş sağlayın.\n",
    "\n",
    "```Parse_front``` fonksiyonu ile, bir önceki fonksiyonda URL'sini tanımlayarak giriş yaptığınız yerdesiniz. Şimdi kullanılacak olan Xpath'lerinizi tanımlayacak, açacak ve belli listeler halinde saklayacaksınız. Bu aşamada ilerlemek istediğiniz linklerinizi de oluşturun. Bu linkleri aşağıdaki komutu kullanarak bir sonraki fonksiyona taşıyabilirsiniz.\n",
    "\n",
    "```yield response.follow(url = url,  callback = self.parse_pages)```\n",
    "\n",
    "Artık ```parse_pages``` fonksiyonuna kadar geldiniz. Bu fonksiyon bir önceki aşamada yarattığınız ve buraya ilettiğiniz her bir URL için belirlediğiniz işlemi yapacak. Yani tekrar bir Xpath tanımlayıp çekmek istediğiniz veriyi işaretleyebilirsiniz. Ardından indirdiğiniz veriyi saklayarak sınıfı terk ediniz.\n",
    "\n",
    "Şimdi tanımladığınız bu sınıfı çalıştırmak için yapmanız gerek onu çağırmak:\n",
    "\n",
    "\n",
    "```process = CrawlerProcess()```\n",
    "\n",
    "```process.crawl(IMDB_Spider)```\n",
    "\n",
    "```process.start()```\n",
    "\n",
    "Bunu yapmadan önce boş listeler tanımlamayı unutmayın, çünkü indirdiğiniz verileri bu boş listelere yazacaksınız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class IMDB_Spider(scrapy.Spider):\n",
    "    name = \"IMDB_Spider\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(url = 'https://m.imdb.com/chart/top', callback = self.parse_front)\n",
    "\n",
    "    def parse_front(self, response):\n",
    "        \n",
    "        movie_names = response.xpath('//h4/text()').extract()\n",
    "        for item in movie_names:\n",
    "            cleaned_string = item.strip()\n",
    "            if cleaned_string != '':\n",
    "                movie_list.append(cleaned_string)\n",
    "        \n",
    "        movie_years = response.xpath('//h4/span[2]/text()').extract()\n",
    "        for item in movie_years:\n",
    "                years.append(item)\n",
    "\n",
    "        movie_links = response.xpath('//*[@id=\"chart-content\"]/div/div/div/a/@href').extract()\n",
    "        for item in movie_links:\n",
    "            first_part_url = 'https://m.imdb.com'\n",
    "            last_part_url = '?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=df09bbba-7a44-41c0-bc85-426ba05a5574&pf_rd_r=R9N3Q0473JZET8YH4S2A&pf_rd_s=top-1&pf_rd_t=15506&pf_rd_i=top&ref_=m_chttp_tt_1'\n",
    "            url = first_part_url + item + last_part_url\n",
    "            links.append(url)\n",
    "            yield response.follow(url = url,  callback = self.parse_pages)\n",
    "            \n",
    "    def parse_pages(self, response):\n",
    "        movie_players = response.xpath('//*[@id=\"__next\"]/main/div/section[1]/div/section/div/div[1]/section[4]/div[2]/div[2]/div/div[2]/a/text()').extract()\n",
    "        players_list.append(movie_players)\n",
    "\n",
    "\n",
    "movie_list = []\n",
    "years = []\n",
    "links = []\n",
    "players_list = []\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(IMDB_Spider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf3e6e-52a6-44c6-8847-c8a63700b9be",
   "metadata": {},
   "source": [
    "### İlk beş satırı görüntüle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1657a43-8456-4436-bdb5-1f9c1cb6712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "links[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49b430-091b-4307-b936-94601bb5612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "years[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a6e1e-0c73-4c77-98bd-f52d903ea2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c2b38-a337-4574-abb9-c6cdb990d298",
   "metadata": {},
   "source": [
    "### Önce dataframe, ardından csv veya json\n",
    "\n",
    "Elinizdeki veriyi önce bir sözlüğe ardından bir pandas DataFrame'ine dönüştürün."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dictimdb = {'movie name':movie_list, 'year':years, 'link':links, 'player_list': players_list}\n",
    "data_imdb = pd.DataFrame(dictimdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0a882-ed9b-430c-b374-7930425c324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb['player_list'][56]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a079d-7c5f-4e2a-b35f-0e92d21f0613",
   "metadata": {},
   "source": [
    "Şimdi de ilgili veriyi csv veya json dosyası olarak bilgisayarınıza kaydedebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beacb402-4e23-4a43-b147-22bd194c3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imdb.to_csv(\"IMDB_Filmlerim.csv\")\n",
    "data_imdb.to_json(\"IMDB_Filmlerim.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
