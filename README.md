# Veri Bilimi - Otomatik Veri Çekme (Python)

Bu sayfa Mimar Sinan Üniversitesi Sosyoloji Konferansı kapsamında gerçekleştirilecek olan, 5 Kasım 2022 tarihli, "Veri Bilimi - Otomatik Veri Çekme" atölyesi için hazırlandı. Python programında yer alan Scrapy kütüphanesi yardımyla otomatik veri çekme (web kazıma - scraping) işlemini anlatıyor. İçerik sosyal bilimciler için hazırlandı. Sunumda Veri Bilimi'ne  genel bir girişten sonra iki tür veri oluşturma tekniği özetlenmekte. Bunlar sırasıyla (tweepy ile) twitter api kullanımı ve (scrapy ile) web kazıma.

"Tweepy" isimli döküman Twitter api'si ile çalışıyor. "Scrapy" dökümanında ise sırasıyla url'yi tanıtma, gerekli Xpath'leri oluşturma, ilgili veriyi çekme ve saklamaya dair detaylar gösteriliyor. Son olarak "Scrapy - Spider" sayfası aynı web kazıma işlemini Spider sınıflandırmasını kullanarak daha hızlı bir şekilde gerçekleştiren kodları içeriyor.

Katılımcıların atölyeden önce "Ön Hazırlık" başlıklı dökümanın üzerinden geçmeleri ve programa hazırlıklı gelmeleri bekleniyor. Katılımcıların Python programı ile çalışmak içi Jupyter Notebook kurmalarına gerek yok. Google halihazırda Colab uygulaması ile bir indirme veya kurma işlemi olmadan Notebook oluşturma ve çalıştırmaya imkan tanıyor. Bunun için takip eden linke tıklamak (https://colab.research.google.com/) ve bir Google hesabına sahip olmak yeterli. İlgili sayfada sıfırdan yeni bir Notebook oluşturabilir, bilgisayarınıza indirdiğiniz ipynb uzantılı bir Notebook dökümanını açabilir, veya Github üzerinden sadece link kopyalarak ilgili dökümana ulaşabilirsiniz.

Yine de Python'ı bilgisayarınıza kurmak isterseniz yukardaki dökümanlar arasından "Kurulum" başlıklı dökümanı inceleyebilirsiniz.

İyi eğlenceler :)
