# Veri Bilimi - Otomatik Veri Çekme (Python)

Bu sayfa Mimar Sinan Üniversitesi Sosyoloji Konferansı kapsamında gerçekleştirilecek olan 5 Kasım 2022 tarihli "Veri Bilimi - Otomatik Veri Çekme" atölyesi için hazırlandı (https://www.msgsusosyolojikonferansi.com/). Atölyemiz en temelde Python programında yer alan Scrapy kütüphanesi yardımyla otomatik veri çekme (web kazıma - scraping) işlemine odaklanıyor. İçerik sosyal bilimciler için hazırlandı. Sunumda Veri Bilimi'ne dair genel bir girişten sonra iki tür veri oluşturma tekniği özetlenmekte. Bunlar sırasıyla (tweepy ile) twitter api kullanımı ve (scrapy ile) web kazıma.

"Tweepy" isimli döküman Twitter api'si ile çalışıyor. "Scrapy" dökümanında ise sırasıyla ilgili URL'leri tanıtma, gerekli Xpath'leri oluşturma, gerekli veriyi çekme ve saklamaya dair detaylar gösteriliyor. Son olarak "Spider" sayfası aynı web kazıma işlemini Spider sınıflandırmasını kullanarak daha hızlı bir şekilde gerçekleştiren kodları içeriyor.

Katılımcıların atölyeden önce "Ön Hazırlık" başlıklı dökümanın üzerinden geçmeleri ve çalışmaya hazırlıklı gelmeleri bekleniyor. Python'ı çalıştırmak için herhangi bir program kurma zorunluluğu yok. Google halihazırda Colab uygulaması ile indirme veya kurma olmadan Jupyter Notebook oluşturma ve çalıştırmaya imkan tanıyor. Bunun için takip eden linke tıklamak (https://colab.research.google.com/) ve bir Google hesabına sahip olmak yeterli. Açılan sayfada sıfırdan yeni bir Notebook oluşturabilir, bilgisayarınıza indirdiğiniz "ipynb" uzantılı herhangi bir Notebook dökümanını "upload" seçeneği ile açabilir, veya sadece Github linkini kopyalarak söz konusu sayfaya ulaşabilirsiniz.

Yine de Python'ı bilgisayarınıza kurmak isterseniz (ki uzun vadeli kullanım için tavsiye edilen seçenek budur) yukardaki dökümanlar arasından "Kurulum, nasıl ve nereden başlamalı" başlıklı sayfayı inceleyebilirsiniz. Ön hazırlığa başlamadan önce hızlıca da olsa bu dökümana göz gezdirmenizi öneririz.

İyi eğlenceler :)
